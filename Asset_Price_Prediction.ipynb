{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN284kOtH1cumk1ElfKJGm+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SidS12345/Quant-projects/blob/main/Asset_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: to use machine learning methods to forecast asset prices\n",
        "\n",
        "In this project, I explore the predictive potential of machine learning in financial markets by applying a range of supervised learning models to historical stock data. I use feature engineering to extract informative signals from price and technical indicators across multiple stocks. These features were used to train and evaluate various models — including linear regression, neural networks and kNN — on their ability to forecast short-term price movements. Performance is assessed using standard classification metrics, both on profits and on variance, enabling comparative analysis of model accuracy and robustness. The project highlights the challenges and opportunities in applying data-driven approaches to quantitative trading."
      ],
      "metadata": {
        "id": "33LGARaF_DeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teGeC-K96n3N",
        "outputId": "69bd4a87-1d8e-4f32-9158-d12b9e973dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=8c7b1274ca7ce06bd214ca82858d602bb5391eda65194abe98267b3c267ba7d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing relevant libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier, LinearRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from ta import trend, momentum"
      ],
      "metadata": {
        "id": "Mh0n527f_ZSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collecting tickers from a range of sectors\n",
        "\n",
        "tickers = [\n",
        "  # Tech\n",
        "  'AAPL',     # Apple\n",
        "  'GOOGL',    # Alphabet\n",
        "  'MSFT',     # Microsoft\n",
        "  'NVDA',     # Nvidia\n",
        "\n",
        "  # Electric Vehicles\n",
        "  'TSLA',     # Tesla\n",
        "\n",
        "  # Finance\n",
        "  'JPM',      # JPMorgan Chase\n",
        "  'BAC',      # Bank of America\n",
        "\n",
        "  # Healthcare\n",
        "  'JNJ',      # Johnson & Johnson\n",
        "  'PFE',      # Pfizer\n",
        "\n",
        "  # Energy\n",
        "  'XOM',      # Exxon Mobil\n",
        "\n",
        "  # Retail / Consumer Goods\n",
        "  'WMT',      # Walmart\n",
        "  'PG',       # Procter & Gamble\n",
        "\n",
        "  # ETFs\n",
        "  'SPY',      # S&P 500 ETF\n",
        "  'QQQ',      # Nasdaq-100 ETF\n",
        "\n",
        "  # Crypto\n",
        "  'BITO',      # Bitcoin Strategy ETF (ProShares)\n",
        "\n",
        "  # Commodity ETF\n",
        "  'GLD'       # Gold\n",
        "]\n",
        "\n",
        "# choosing start and end date, taking today's date to be the end date and giving us 1500 days of stock data\n",
        "today = datetime.today()\n",
        "yesterday = today - timedelta(days = 1)\n",
        "end_date = today - timedelta(days = 30)\n",
        "start_date = end_date - timedelta(days = 1500)"
      ],
      "metadata": {
        "id": "LjrDsMPG0GiN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "11a980d1-0463-4bfb-c322-fc2cd0ee1645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'datetime' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3770636579.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# choosing start and end date, taking today's date to be the end date and giving us 1500 days of stock data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtoday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0myesterday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoday\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoday\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_feature_dfs = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "  # Download price data\n",
        "  data = yf.download(ticker, start=start_date, end=end_date, auto_adjust=False)\n",
        "\n",
        "  df = pd.DataFrame(index=data.index)\n",
        "  df['close'] = data['Close']\n",
        "\n",
        "  # Returns & lags\n",
        "  df['pct_returns'] = 100 * (df['close'] - df['close'].shift(1)) / df['close'].shift(1)\n",
        "  df['lag_1'] = df['pct_returns'].shift(1)\n",
        "  df['lag_5'] = df['pct_returns'].shift(5)\n",
        "\n",
        "  # Moving Averages\n",
        "  df['sma_5'] = df['close'].rolling(window=5).mean()\n",
        "  df['sma_10'] = df['close'].rolling(window=10).mean()\n",
        "  df['sma_20'] = df['close'].rolling(window=20).mean()\n",
        "\n",
        "  # Volatility\n",
        "  df['volatility_10'] = df['pct_returns'].rolling(window=10).std()\n",
        "  df['volatility_20'] = df['pct_returns'].rolling(window=20).std()\n",
        "\n",
        "  # Exponential Moving Averages\n",
        "  df['ema_10'] = trend.EMAIndicator(close=df['close'], window=10).ema_indicator()\n",
        "  df['ema_20'] = trend.EMAIndicator(close=df['close'], window=20).ema_indicator()\n",
        "\n",
        "  # MACD\n",
        "  macd = trend.MACD(close=df['close'])\n",
        "  df['macd'] = macd.macd()\n",
        "  df['macd_signal'] = macd.macd_signal()\n",
        "  df['macd_diff'] = macd.macd_diff()\n",
        "\n",
        "  # RSI\n",
        "  df['rsi'] = momentum.RSIIndicator(close=df['close'], window=14).rsi()\n",
        "\n",
        "  # ADX\n",
        "  high = pd.Series(data['High'].values.flatten(), index=data.index)\n",
        "  low = pd.Series(data['Low'].values.flatten(), index=data.index)\n",
        "  close = pd.Series(data['Close'].values.flatten(), index=data.index)\n",
        "  adx = trend.ADXIndicator(high, low, close)\n",
        "  df['adx'] = adx.adx()\n",
        "\n",
        "  # Drop NaNs (from indicators with lags/rolling)\n",
        "  df = df.dropna()\n",
        "\n",
        "  # Scale features\n",
        "  features = df.copy()\n",
        "  scaler = StandardScaler()\n",
        "  scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "  df_scaled = pd.DataFrame(scaled_features, index=features.index, columns=features.columns).dropna()\n",
        "  # Store in dictionary\n",
        "  ticker_feature_dfs[ticker] = {\n",
        "    'features': df_scaled,\n",
        "    'raw features': df,\n",
        "    'scaler': scaler,\n",
        "    'mean': df['close'].mean(),\n",
        "    'std': df['close'].std()\n",
        "  }\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "cHWf2HKO4TZK",
        "outputId": "bdf10d50-08f1-45d4-d9c7-55fbb3dcc1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tickers' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1970926557.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mticker_feature_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtickers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;31m# Download price data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_adjust\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tickers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def rescale(dataset, std, mean):\n",
        "  return dataset * std + mean\n",
        "\n",
        "# Create model\n",
        "def create_model(ticker, ticker_feature_dfs, model):\n",
        "  df_scaled = ticker_feature_dfs[ticker]['features'].copy()\n",
        "  raw_df = ticker_feature_dfs[ticker]['raw features']\n",
        "  mean = ticker_feature_dfs[ticker]['mean']\n",
        "  std = ticker_feature_dfs[ticker]['std']\n",
        "\n",
        "  df_scaled['target'] = df_scaled['close'].shift(-1)\n",
        "  df_scaled = df_scaled.dropna()\n",
        "\n",
        "  X = df_scaled.drop(['target'], axis=1)\n",
        "  y = df_scaled['target']\n",
        "\n",
        "  seed = 10 # random state of split. Can evaluate how different splits affect our results. Choose if we use seed or not\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "  target = rescale(y_test.to_numpy(), std, mean)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "  model_preds = model.predict(X_test)\n",
        "  model_preds = rescale(model_preds, std, mean)\n",
        "\n",
        "  return model_preds, X_test, target, model, raw_df"
      ],
      "metadata": {
        "id": "oAeRhjC1ZuQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will implement a simple trading strategy on our predicted data - if the predicted close price is above the current close price, we will buy. Otherwise, we will sell. We will neutralise the position on the next day, and then advance to the next predicted datapoint. This will help us understand a bit about how useful our predictions may be for a trading bot"
      ],
      "metadata": {
        "id": "WrgiU79lwJWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def simple_trading(preds, X_test, y_test):\n",
        "  bought = 0\n",
        "  sold = 0\n",
        "  no_trade = 0\n",
        "  profit = 0\n",
        "  profitable_trades = 0\n",
        "  unprofitable_trades = 0\n",
        "  break_even_trades = 0\n",
        "  profits = []\n",
        "  losses = []\n",
        "  for i in range(len(preds)):\n",
        "    date = X_test.index[i]\n",
        "    close_today = X_test.iloc[i]['close']\n",
        "    pred = preds[i]\n",
        "    next_close = y_test.iloc[i]\n",
        "    if pred > close_today:\n",
        "      bought += 1\n",
        "      PnL = next_close - close_today\n",
        "    elif pred < close_today:\n",
        "      sold += 1\n",
        "      PnL = close_today - next_close\n",
        "    else:\n",
        "      no_trade += 1\n",
        "    if PnL > 0:\n",
        "      profitable_trades += 1\n",
        "      profits.append(PnL)\n",
        "    elif PnL < 0:\n",
        "      unprofitable_trades += 1\n",
        "      losses.append(-PnL)\n",
        "    else:\n",
        "      break_even_trades += 1\n",
        "    profit += PnL\n",
        "  return profit, profitable_trades, unprofitable_trades\n",
        "'''"
      ],
      "metadata": {
        "id": "PNW1WDKTU0qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def simple_trading(preds, X_test, raw_df):\n",
        "  bought = 0\n",
        "  sold = 0\n",
        "  profit = 0\n",
        "  profitable_trades = 0\n",
        "  unprofitable_trades = 0\n",
        "  break_even_trades = 0\n",
        "  profits = []\n",
        "  losses = []\n",
        "\n",
        "  for i in range(len(preds)):\n",
        "    date = X_test.index[i]\n",
        "    day = date.dayofweek\n",
        "    next_day_add = 3 if day == 4 else 1\n",
        "    next_date = date + timedelta(days=next_day_add)\n",
        "\n",
        "    if next_date in raw_df.index:\n",
        "      pred = preds[i]\n",
        "      close_today = raw_df.loc[date, 'close']\n",
        "      next_close = raw_df.loc[next_date, 'close']\n",
        "      if pred > close_today:\n",
        "        bought += 1\n",
        "        PnL = next_close - close_today\n",
        "      else:\n",
        "        sold += 1\n",
        "        PnL = close_today - next_close\n",
        "      if PnL > 0:\n",
        "        profitable_trades += 1\n",
        "        profits.append(PnL)\n",
        "      elif PnL < 0:\n",
        "        unprofitable_trades += 1\n",
        "        losses.append(-PnL)\n",
        "      else:\n",
        "        break_even_trades += 1\n",
        "      profit += PnL\n",
        "\n",
        "  return profit, profits, losses, break_even_trades\n"
      ],
      "metadata": {
        "id": "eZpCCTZLxDWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Giving the option to choose model, rather than just sticking simply to linear regression\n",
        "# Can adjust hyperparameters within this choose model function\n",
        "def choose_model(n):\n",
        "  lin_reg = LinearRegression()\n",
        "  rf = RandomForestRegressor(n_estimators=100)\n",
        "  grad_boost = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
        "  mlp = MLPRegressor(hidden_layer_sizes=(100,100), max_iter=500)\n",
        "  knn = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "  global list_of_models\n",
        "  list_of_models = [lin_reg, rf, grad_boost, mlp, knn]\n",
        "\n",
        "  global model_names\n",
        "  model_names = ['lin_reg   ', 'rf        ', 'grad_boost', 'mlp       ', 'knn       ']\n",
        "# list_of_models = [lin_reg]\n",
        "  return list_of_models[n]"
      ],
      "metadata": {
        "id": "24c_Por7ixlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nothing = choose_model(1)"
      ],
      "metadata": {
        "id": "sV7gAr21nuP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_profits(tickers, ticker_feature_dfs, model):\n",
        "  ticker_profs = {\n",
        "      ticker: {\n",
        "          'profit': 0,\n",
        "          'profitable trades': None,\n",
        "          'unprofitable trades': None,\n",
        "          'trained model': None,\n",
        "          'start prices': None,\n",
        "          'predicted prices': None,\n",
        "          'actual prices': None,\n",
        "          'break even trades': None\n",
        "      } for ticker in tickers\n",
        "  }\n",
        "  for ticker in tickers:\n",
        "    model_preds, X_test, y_test, trained_model, raw_df = create_model(ticker, ticker_feature_dfs, model)\n",
        "    profit, profits, losses, break_even_trades = simple_trading(model_preds, X_test, raw_df)\n",
        "    ticker_profs[ticker]['profit'] = profit\n",
        "    ticker_profs[ticker]['profits'] = profits\n",
        "    ticker_profs[ticker]['losses'] = losses\n",
        "    ticker_profs[ticker]['trained model'] = trained_model\n",
        "\n",
        "    mean = ticker_feature_dfs[ticker]['mean']\n",
        "    std = ticker_feature_dfs[ticker]['std']\n",
        "    ticker_profs[ticker]['start prices'] = rescale(X_test['close'], std, mean)\n",
        "    ticker_profs[ticker]['predicted prices'] = model_preds\n",
        "    ticker_profs[ticker]['actual prices'] = y_test\n",
        "    ticker_profs[ticker]['break even trades'] = break_even_trades\n",
        "\n",
        "#  for ticker, profit in ticker_profs.items():\n",
        "#    print(f\"{ticker}: {profit}\")\n",
        "  return ticker_profs\n",
        "'''model = choose_model(4)\n",
        "ticker_profs = run_profits(tickers, ticker_feature_dfs, model)\n",
        "for ticker in tickers:\n",
        "  print(f\"{ticker}: {ticker_profs[ticker]['profit']}\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ZFCIRmUHe5BO",
        "outputId": "65c3a357-4cbd-42da-e951-e0de1943ed5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model = choose_model(4)\\nticker_profs = run_profits(tickers, ticker_feature_dfs, model)\\nfor ticker in tickers:\\n  print(f\"{ticker}: {ticker_profs[ticker][\\'profit\\']}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keeping note on how long it takes each ML model to train and run once, where we have 16 assets and creating a lot of dictionaries\n",
        "\n",
        "model 0 - 0s\n",
        "\n",
        "model 1 - 24s\n",
        "\n",
        "model 2 - 13s\n",
        "\n",
        "model 3 - 8s\n",
        "\n",
        "model 4 - 0s\n"
      ],
      "metadata": {
        "id": "Gng2AQ6fyicR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating profit of each model once:\n",
        "\n",
        "def model_statistics(tickers, ticker_feature_dfs):\n",
        "  model_dict = {\n",
        "    i: {\n",
        "        'model': None,\n",
        "        'model type': None,\n",
        "        'overall profit': 0,\n",
        "        'all profitable trades': None,\n",
        "        'all unprofitable trades': None,\n",
        "        'all trained models': None,\n",
        "        'all start prices': None,\n",
        "        'all predicted prices': None,\n",
        "        'all actual prices': None,\n",
        "        'total break even trades': None\n",
        "    }\n",
        "    for i in range(len(list_of_models))\n",
        "  }\n",
        "\n",
        "  for i in range(len(list_of_models)):\n",
        "    model = choose_model(i)\n",
        "    ticker_profs_model = run_profits(tickers, ticker_feature_dfs, model)\n",
        "    model_dict[i]['model'] = model\n",
        "    model_dict[i]['model type'] = model_names[i]\n",
        "    model_dict[i]['overall profit'] = sum([ticker_profs_model[ticker]['profit'] for ticker in tickers])\n",
        "    model_dict[i]['all profits'] = [ticker_profs_model[ticker]['profits'] for ticker in tickers]\n",
        "    model_dict[i]['all losses'] = [ticker_profs_model[ticker]['losses'] for ticker in tickers]\n",
        "    model_dict[i]['all trained models'] = [ticker_profs_model[ticker]['trained model'] for ticker in tickers]\n",
        "    model_dict[i]['all start prices'] = [ticker_profs_model[ticker]['start prices'] for ticker in tickers]\n",
        "    model_dict[i]['all predicted prices'] = [ticker_profs_model[ticker]['predicted prices'] for ticker in tickers]\n",
        "    model_dict[i]['all actual prices'] = [ticker_profs_model[ticker]['actual prices'] for ticker in tickers]\n",
        "    model_dict[i]['total break even trades'] = [ticker_profs_model[ticker]['break even trades'] for ticker in tickers]\n",
        "\n",
        "  return model_dict"
      ],
      "metadata": {
        "id": "q8B8KhtfgkpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Now simulating this many times and seeing how much overall profit we make on average\n",
        "# Note - running this with 10 iterations takes about 10 minutes; currently very inefficient look for more efficient solutions\n",
        "iterations = 1\n",
        "iteration_profits = np.zeros(iterations)\n",
        "per_ticker_profits = {\n",
        "    ticker: 0 for ticker in tickers\n",
        "}\n",
        "\n",
        "overall_model_profits = {\n",
        "    i: 0 for i in range(len(list_of_models))\n",
        "}\n",
        "\n",
        "for i in range(iterations):\n",
        "  model_dict = model_statistics(tickers, ticker_feature_dfs)\n",
        "  for j in range(len(list_of_models)):\n",
        "    overall_model_profits[j] += model_dict[j]['overall profit']/iterations\n",
        "\n",
        "for i, profit in overall_model_profits.items():\n",
        "  print(f\"Model {i}: {profit}\")\n",
        "\n",
        "'''\n",
        "\n",
        "'''for j in range(len(list_of_models)):\n",
        "  model = choose_model(j)\n",
        "  overall_profits = 0\n",
        "  for i in range(iterations):\n",
        "    ticker_profs = run_profits(tickers, ticker_feature_dfs, model)\n",
        "    iteration_profits[i] = sum(ticker_profs.values())\n",
        "    for ticker, profit in ticker_profs.items():\n",
        "      per_ticker_profits[ticker] += profit\n",
        "    for ticker, profit in ticker_profs.items():\n",
        "      overall_profits += profit/iterations\n",
        "\n",
        "\n",
        "  model_profits[j] = overall_profits\n",
        "#  print(f\"{ticker}: {profit/iterations}\")\n",
        "for model, profit in model_profits.items():\n",
        "  print(f\"{model}: {profit}\")\n",
        "\n",
        "\n",
        "# Alternatively, we can find the average across a larger number of timestamps for a specific model\n",
        "\n",
        "model = choose_model(4)\n",
        "overall_profits = 0\n",
        "iterations = 100\n",
        "for i in range(iterations):\n",
        "  ticker_profs = run_profits(tickers, ticker_feature_dfs, model)\n",
        "  iteration_profits[i] = sum(ticker_profs.values())\n",
        "  for ticker, profit in ticker_profs.items():\n",
        "    per_ticker_profits[ticker] += profit\n",
        "    overall_profits += profit/iterations\n",
        "for ticker, profit in per_ticker_profits.items():\n",
        "  print(f\"{ticker}: {profit/iterations}\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "yKWrFaIBW6Oe",
        "outputId": "ca410d85-439b-4d6c-935c-91b26bc6f155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 0: -292.24089765548706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for j in range(len(list_of_models)):\\n  model = choose_model(j)  \\n  overall_profits = 0\\n  for i in range(iterations):\\n    ticker_profs = run_profits(tickers, ticker_feature_dfs, model)\\n    iteration_profits[i] = sum(ticker_profs.values())\\n    for ticker, profit in ticker_profs.items():\\n      per_ticker_profits[ticker] += profit\\n    for ticker, profit in ticker_profs.items():\\n      overall_profits += profit/iterations\\n  \\n\\n  model_profits[j] = overall_profits\\n#  print(f\"{ticker}: {profit/iterations}\")\\nfor model, profit in model_profits.items():\\n  print(f\"{model}: {profit}\")\\n\\n\\n# Alternatively, we can find the average across a larger number of timestamps for a specific model\\n\\nmodel = choose_model(4)\\noverall_profits = 0\\niterations = 100\\nfor i in range(iterations):\\n  ticker_profs = run_profits(tickers, ticker_feature_dfs, model)\\n  iteration_profits[i] = sum(ticker_profs.values())\\n  for ticker, profit in ticker_profs.items():\\n    per_ticker_profits[ticker] += profit\\n    overall_profits += profit/iterations\\nfor ticker, profit in per_ticker_profits.items():\\n  print(f\"{ticker}: {profit/iterations}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = model_statistics(tickers, ticker_feature_dfs)\n",
        "\n",
        "# Hard coding in our dictionary so that we can make running time of compare_models shorter"
      ],
      "metadata": {
        "id": "dsmapi1qlHgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we want to compare different ML models, using a range of metrics\n",
        "\n",
        "def compare_models():\n",
        "# model_dict = model_statistics(tickers, ticker_feature_dfs)\n",
        "  comparison_dict = {\n",
        "      i: {\n",
        "          'model type': None,\n",
        "          # 'trained ticker models': None,\n",
        "\n",
        "          # Trading profit performance metrics\n",
        "          'number of trades': None,\n",
        "          'PnL': None,\n",
        "          'win rate': None,\n",
        "          'average profit per trade': None,\n",
        "          'profit standard deviation': None,\n",
        "          'profit factor': None,\n",
        "          'average profit per successful trade': None,\n",
        "          'average loss per unsuccessful trade': None,\n",
        "          'max profit': None,\n",
        "          'max loss': None,\n",
        "          'sharpe ratio': None,\n",
        "\n",
        "          # Prediction accuracy metrics\n",
        "          'mae': None,\n",
        "          'rmse': None,\n",
        "          'r2': None,\n",
        "          'correlation': None,\n",
        "          'mape': None,\n",
        "          'explained variance': None,\n",
        "\n",
        "          # Using more general classification accuracy metrics\n",
        "          'accuracy': None,\n",
        "          'precision': None,\n",
        "          'recall': None,\n",
        "          'f1 score': None,\n",
        "\n",
        "          # Can also add other metrics to do with model specifically, e.g. how hyperparameters or random seed affect performance\n",
        "\n",
        "\n",
        "\n",
        "      }\n",
        "      for i in range(len(list_of_models))\n",
        "  }\n",
        "  for i in range(len(list_of_models)):\n",
        "\n",
        "    # Profit metrics\n",
        "    profits = model_dict[i]['all profits']\n",
        "    all_profits = np.concatenate(profits)\n",
        "    losses = model_dict[i]['all losses']\n",
        "    all_losses = np.concatenate(losses)\n",
        "\n",
        "    num_of_wins = len(all_profits)\n",
        "    num_of_losses = len(all_losses)\n",
        "    num_of_break_evens = sum(model_dict[i]['total break even trades'])\n",
        "    num_of_trades = num_of_wins + num_of_losses + num_of_break_evens\n",
        "\n",
        "    total_profits = sum(all_profits)\n",
        "    total_losses = sum(all_losses)\n",
        "    total_PnL = total_profits - total_losses\n",
        "    win_rate = num_of_wins/num_of_trades\n",
        "    average_PnL = total_PnL/num_of_trades\n",
        "    profit_std = np.std(np.concatenate((all_profits,-all_losses)))\n",
        "    profit_factor = total_profits/total_losses\n",
        "    average_profit_per_successful_trade = total_profits/num_of_wins\n",
        "    average_loss_per_unsuccessful_trade = total_losses/num_of_losses\n",
        "    max_profit = max(all_profits)\n",
        "    max_loss = max(all_losses)\n",
        "    sharpe_ratio = average_PnL/profit_std\n",
        "\n",
        "    # Prediction accuracy metrics\n",
        "    y_test = np.concatenate(model_dict[i]['all actual prices'])\n",
        "    y_pred = np.concatenate(model_dict[i]['all predicted prices'])\n",
        "    y_start = np.concatenate(model_dict[i]['all start prices'])\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    correlation = np.corrcoef(y_test, y_pred)[0,1]\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "    explained_variance = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "    # Metrics for assessing price movement (up/down) - use positive to mean price increased\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    for j in range(len(y_test)):\n",
        "      if y_pred[j] > y_start[j]:\n",
        "        if y_test[j] > y_start[j]:\n",
        "          TP += 1\n",
        "        else:\n",
        "          FP += 1\n",
        "      else:\n",
        "        if y_test[j] < y_start[j]:\n",
        "          TN += 1\n",
        "        else:\n",
        "          FN += 1\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "    precision = TP / (TP + FP)\n",
        "    recall = TP / (TP + FN)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    comparison_dict[i]['model type'] = model_dict[i]['model type']\n",
        "#   comparison_dict[i]['trained ticker models'] = model_dict[i]['all trained models']     -     Commented out to make dictionary more readable\n",
        "    comparison_dict[i]['number of trades'] = num_of_trades\n",
        "    comparison_dict[i]['PnL'] = total_PnL\n",
        "    comparison_dict[i]['win rate'] = win_rate\n",
        "    comparison_dict[i]['average profit per trade'] = average_PnL\n",
        "    comparison_dict[i]['profit standard deviation'] = profit_std\n",
        "    comparison_dict[i]['profit factor'] = profit_factor\n",
        "    comparison_dict[i]['average profit per successful trade'] = average_profit_per_successful_trade\n",
        "    comparison_dict[i]['average loss per unsuccessful trade'] = average_loss_per_unsuccessful_trade\n",
        "    comparison_dict[i]['max profit'] = max_profit\n",
        "    comparison_dict[i]['max loss'] = max_loss\n",
        "    comparison_dict[i]['sharpe ratio'] = sharpe_ratio\n",
        "\n",
        "    comparison_dict[i]['mae'] = mae\n",
        "    comparison_dict[i]['rmse'] = rmse\n",
        "    comparison_dict[i]['r2'] = r2\n",
        "    comparison_dict[i]['correlation'] = correlation\n",
        "    comparison_dict[i]['mape'] = mape\n",
        "    comparison_dict[i]['explained variance'] = explained_variance\n",
        "\n",
        "    comparison_dict[i]['accuracy'] = accuracy\n",
        "    comparison_dict[i]['precision'] = precision\n",
        "    comparison_dict[i]['recall'] = recall\n",
        "    comparison_dict[i]['f1 score'] = f1_score\n",
        "\n",
        "  return comparison_dict\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lg03DvyVg6vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_floats(obj, decimals=2):\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: format_floats(v, decimals) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [format_floats(item, decimals) for item in obj]\n",
        "    elif isinstance(obj, (float, np.floating)):\n",
        "        return f\"{obj:.{decimals}f}\"\n",
        "    else:\n",
        "        return obj\n"
      ],
      "metadata": {
        "id": "7veu8tqCrz62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "returned = format_floats(compare_models())\n",
        "for item, value in returned.items():\n",
        "  print(f\"{item}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA5CkLTOr3iD",
        "outputId": "91cdb982-14a8-414d-f079-65eb0216ca32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: {'model type': 'lin_reg   ', 'number of trades': 3101, 'PnL': '-400.70', 'win rate': '0.50', 'average profit per trade': '-0.13', 'profit standard deviation': '3.89', 'profit factor': '0.89', 'average profit per successful trade': '1.99', 'average loss per unsuccessful trade': '2.29', 'max profit': '26.45', 'max loss': '47.35', 'sharpe ratio': '-0.03', 'mae': '2.16', 'rmse': '4.00', 'r2': '1.00', 'correlation': '1.00', 'mape': '0.01', 'explained variance': '1.00', 'accuracy': '0.50', 'precision': '0.52', 'recall': '0.58', 'f1 score': '0.55'}\n",
            "1: {'model type': 'rf        ', 'number of trades': 3101, 'PnL': '374.20', 'win rate': '0.51', 'average profit per trade': '0.12', 'profit standard deviation': '3.89', 'profit factor': '1.12', 'average profit per successful trade': '2.20', 'average loss per unsuccessful trade': '2.07', 'max profit': '47.35', 'max loss': '31.53', 'sharpe ratio': '0.03', 'mae': '2.33', 'rmse': '4.20', 'r2': '1.00', 'correlation': '1.00', 'mape': '0.02', 'explained variance': '1.00', 'accuracy': '0.51', 'precision': '0.54', 'recall': '0.54', 'f1 score': '0.54'}\n",
            "2: {'model type': 'grad_boost', 'number of trades': 3101, 'PnL': '21.83', 'win rate': '0.50', 'average profit per trade': '0.01', 'profit standard deviation': '3.89', 'profit factor': '1.01', 'average profit per successful trade': '2.13', 'average loss per unsuccessful trade': '2.15', 'max profit': '47.35', 'max loss': '31.68', 'sharpe ratio': '0.00', 'mae': '2.32', 'rmse': '4.21', 'r2': '1.00', 'correlation': '1.00', 'mape': '0.02', 'explained variance': '1.00', 'accuracy': '0.50', 'precision': '0.53', 'recall': '0.54', 'f1 score': '0.53'}\n",
            "3: {'model type': 'mlp       ', 'number of trades': 3101, 'PnL': '-112.72', 'win rate': '0.50', 'average profit per trade': '-0.04', 'profit standard deviation': '3.89', 'profit factor': '0.97', 'average profit per successful trade': '2.11', 'average loss per unsuccessful trade': '2.16', 'max profit': '31.53', 'max loss': '47.35', 'sharpe ratio': '-0.01', 'mae': '2.81', 'rmse': '4.90', 'r2': '1.00', 'correlation': '1.00', 'mape': '0.02', 'explained variance': '1.00', 'accuracy': '0.49', 'precision': '0.52', 'recall': '0.51', 'f1 score': '0.51'}\n",
            "4: {'model type': 'knn       ', 'number of trades': 3101, 'PnL': '1133.26', 'win rate': '0.56', 'average profit per trade': '0.37', 'profit standard deviation': '3.87', 'profit factor': '1.41', 'average profit per successful trade': '2.24', 'average loss per unsuccessful trade': '2.01', 'max profit': '31.53', 'max loss': '47.35', 'sharpe ratio': '0.09', 'mae': '3.69', 'rmse': '6.43', 'r2': '1.00', 'correlation': '1.00', 'mape': '0.03', 'explained variance': '1.00', 'accuracy': '0.56', 'precision': '0.58', 'recall': '0.58', 'f1 score': '0.58'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having issue with data volatility - results of our predictions seem to vary massively based on what our train test split is. Maybe because sometimes the actual test data is not so good as opposed to our model being bad, but unsure\n",
        "\n",
        "See what fields in model_dict I'm using for comparison_dict, and which ones I can get rid of / implement more effectively"
      ],
      "metadata": {
        "id": "XbjmJG628NGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running the models on the last 30 days of test data\n",
        "\n",
        "closing_prices = pd.DataFrame()\n",
        "for ticker in tickers:\n",
        "  data = yf.download(ticker, start = end_date, end = today)\n",
        "  closing_prices[ticker] = data[\"Close\"]\n",
        "\n",
        "# Now cleaning the data so that we can operate on it successfully\n",
        "\n",
        "closing_prices = closing_prices.dropna(how='any')\n",
        "closing_prices = closing_prices.drop_duplicates()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMZUpGCsgkYP",
        "outputId": "4512c7d5-0c61-4fe8-8878-cbf20df90c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-31-2817143249.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start = end_date, end = today)\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_feature_dfs_predict = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "  # Download price data\n",
        "  data = yf.download(ticker, start=start_date, end=today)\n",
        "\n",
        "  df = pd.DataFrame(index=data.index)\n",
        "  df['close'] = data['Close']\n",
        "\n",
        "  # Returns & lags\n",
        "  df['pct_returns'] = 100 * (df['close'] - df['close'].shift(1)) / df['close'].shift(1)\n",
        "  df['lag_1'] = df['pct_returns'].shift(1)\n",
        "  df['lag_5'] = df['pct_returns'].shift(5)\n",
        "\n",
        "  # Moving Averages\n",
        "  df['sma_5'] = df['close'].rolling(window=5).mean()\n",
        "  df['sma_10'] = df['close'].rolling(window=10).mean()\n",
        "  df['sma_20'] = df['close'].rolling(window=20).mean()\n",
        "\n",
        "  # Volatility\n",
        "  df['volatility_10'] = df['pct_returns'].rolling(window=10).std()\n",
        "  df['volatility_20'] = df['pct_returns'].rolling(window=20).std()\n",
        "\n",
        "  # Exponential Moving Averages\n",
        "  df['ema_10'] = trend.EMAIndicator(close=df['close'], window=10).ema_indicator()\n",
        "  df['ema_20'] = trend.EMAIndicator(close=df['close'], window=20).ema_indicator()\n",
        "\n",
        "  # MACD\n",
        "  macd = trend.MACD(close=df['close'])\n",
        "  df['macd'] = macd.macd()\n",
        "  df['macd_signal'] = macd.macd_signal()\n",
        "  df['macd_diff'] = macd.macd_diff()\n",
        "\n",
        "  # RSI\n",
        "  df['rsi'] = momentum.RSIIndicator(close=df['close'], window=14).rsi()\n",
        "\n",
        "  # ADX\n",
        "  high = pd.Series(data['High'].values.flatten(), index=data.index)\n",
        "  low = pd.Series(data['Low'].values.flatten(), index=data.index)\n",
        "  close = pd.Series(data['Close'].values.flatten(), index=data.index)\n",
        "  adx = trend.ADXIndicator(high, low, close)\n",
        "  df['adx'] = adx.adx()\n",
        "\n",
        "  # Drop NaNs (from indicators with lags/rolling)\n",
        "  df = df.dropna()\n",
        "\n",
        "  # Scale features\n",
        "  features = df.copy()\n",
        "  scaler = ticker_feature_dfs[ticker]['scaler']\n",
        "  scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "  df_scaled = pd.DataFrame(scaled_features, index=features.index, columns=features.columns).dropna()\n",
        "  # Store in dictionary\n",
        "  ticker_feature_dfs_predict[ticker] = {\n",
        "    'features': df_scaled,\n",
        "    'raw features': df,\n",
        "    'scaler': scaler,\n",
        "    'mean': df['close'].mean(),\n",
        "    'std': df['close'].std()\n",
        "  }\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qIKcv70hdLj",
        "outputId": "679b9306-b3eb-4e0b-8483-095bb4bdb932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-32-284466362.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=today)\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure end_date is a datetime object\n",
        "end_date = pd.to_datetime(end_date)\n",
        "\n",
        "# Filter each ticker's data to only include rows from end_date onwards\n",
        "for ticker in ticker_feature_dfs_predict:\n",
        "    ticker_feature_dfs_predict[ticker]['features'] = ticker_feature_dfs_predict[ticker]['features'].loc[end_date:]\n",
        "    ticker_feature_dfs_predict[ticker]['raw features'] = ticker_feature_dfs_predict[ticker]['raw features'].loc[end_date:]\n"
      ],
      "metadata": {
        "id": "1z9MWF_wjlHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running each model from model_dict on our predict data and seeing what profits we get\n",
        "\n",
        "def predict_profits(ticker_feature_dfs_predict, model_index):\n",
        "  overall_profit = 0\n",
        "  for i in range(len(tickers)):\n",
        "    model = model_dict[model_index]['all trained models'][i]\n",
        "    preds = model.predict(ticker_feature_dfs_predict[tickers[i]]['features'])\n",
        "    X_test = ticker_feature_dfs_predict[tickers[i]]['features']\n",
        "    raw_df = ticker_feature_dfs_predict[tickers[i]]['raw features']\n",
        "    profit, _, _, _ = simple_trading(preds, X_test, raw_df)\n",
        "    overall_profit += profit\n",
        "  return overall_profit"
      ],
      "metadata": {
        "id": "J-NOxW0QkGy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(len(list_of_models)):\n",
        "  model_type = model_names[j]\n",
        "  overall_profit = predict_profits(ticker_feature_dfs_predict, j)\n",
        "  print(f\"{model_type} made {overall_profit}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Feb_-Ykin7Dr",
        "outputId": "0374854d-915c-4c8b-c03c-e0ae4a41699a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lin_reg    made -224.87607765197754\n",
            "rf         made -224.87607765197754\n",
            "grad_boost made -224.87607765197754\n",
            "mlp        made -224.87607765197754\n",
            "knn        made -224.87607765197754\n"
          ]
        }
      ]
    }
  ]
}